{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ['https_proxy'] = '127.0.0.1:1080'\n",
    "os.environ['http_proxy'] = '127.0.0.1:1080'\n",
    "CACHE_DIR = \"/home/liuchao/shushanfu/LMOps/data/huggingface_cache\"\n",
    "\n",
    "# only get one packet\n",
    "dataset = datasets.load_dataset('bigcode/starcoderdata', split='train',data_files=\"python/train-00000-of-00059.parquet\",trust_remote_code=True,cache_dir=CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['max_stars_repo_path', 'max_stars_repo_name', 'max_stars_count', 'id', 'content'],\n",
       "    num_rows: 218079\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<reponame>SDhuangao/netease-cloud-music-dl\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import requests\n",
      "\n",
      "from ncm.encrypt import encrypted_request\n",
      "from ncm.constants import headers\n",
      "from ncm.constants import song_download_url\n",
      "from ncm.constants import get_song_url\n",
      "from ncm.constants import get_album_url\n",
      "from ncm.constants import get_artist_url\n",
      "from ncm.constants import get_playlist_url\n",
      "\n",
      "\n",
      "class CloudApi(object):\n",
      "\n",
      "    def __init__(self, timeout=30):\n",
      "        super().__init__()\n",
      "        self.session = requests.session()\n",
      "        self.session.headers.update(headers)\n",
      "        self.timeout = timeout\n",
      "\n",
      "    def get_request(self, url):\n",
      "\n",
      "        response = self.session.get(url, timeout=self.timeout)\n",
      "        result = response.json()\n",
      "        if result['code'] != 200:\n",
      "            print('Return {} when try to get {}'.format(result, url))\n",
      "        else:\n",
      "            return result\n",
      "\n",
      "    def post_request(self, url, params):\n",
      "\n",
      "        data = encrypted_request(params)\n",
      "        response = self.session.post(url, data=data, timeout=self.timeout)\n",
      "        result = response.json()\n",
      "        if result['code'] != 200:\n",
      "            print('Return {} when try to post {} => {}'.format(result, params, url))\n",
      "        else:\n",
      "            return result\n",
      "\n",
      "    def get_song(self, song_id):\n",
      "        \"\"\"\n",
      "        Get song info by song id\n",
      "        :param song_id:\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        url = get_song_url(song_id)\n",
      "        result = self.get_request(url)\n",
      "\n",
      "        return result['songs'][0]\n",
      "\n",
      "    def get_album_songs(self, album_id):\n",
      "        \"\"\"\n",
      "        Get all album songs info by album id\n",
      "        :param album_id:\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        url = get_album_url(album_id)\n",
      "        result = self.get_request(url)\n",
      "\n",
      "        return result['album']['songs']\n",
      "\n",
      "    def get_song_url(self, song_id, bit_rate=320000):\n",
      "        \"\"\"Get a song's download url.\n",
      "        :params song_id: song id<int>.\n",
      "        :params bit_rate: {'MD 128k': 128000, 'HD 320k': 320000}\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        url = song_download_url\n",
      "        csrf = ''\n",
      "        params = {'ids': [song_id], 'br': bit_rate, 'csrf_token': csrf}\n",
      "        result = self.post_request(url, params)\n",
      "        song_url = result['data'][0]['url']\n",
      "        return song_url\n",
      "\n",
      "    def get_hot_songs(self, artist_id):\n",
      "        \"\"\"\n",
      "        Get a artist 50 hot songs\n",
      "        :param artist_id:\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        url = get_artist_url(artist_id)\n",
      "        result = self.get_request(url)\n",
      "        return result['hotSongs']\n",
      "\n",
      "    def get_playlist_songs(self, playlist_id):\n",
      "        \"\"\"\n",
      "        Get a public playlist all songs\n",
      "        :param playlist_id:\n",
      "        :return:\n",
      "        \"\"\"\n",
      "               \n",
      "        url = get_playlist_url(playlist_id)\n",
      "        result = self.get_request(url)\n",
      "        return result['playlist']['trackIds'], result['playlist']['name']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2019][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordCount: 88962456\n",
      "Newlines: 28874698\n",
      "Spaces: 249641192\n",
      "Tabs: 1872325\n"
     ]
    }
   ],
   "source": [
    "wordCount = 0\n",
    "newline_count = 0  # 回车 \\n\n",
    "space_count = 0    # 空格\n",
    "tab_count = 0      # 制表符 \\t\n",
    "for data in dataset:\n",
    "    content = data['content']\n",
    "    # 拆分成单词并更新计数\n",
    "    wordCount += len(content.split())\n",
    "    newline_count += content.count('\\n')\n",
    "    space_count += content.count(' ')\n",
    "    tab_count += content.count('\\t')\n",
    "print(f\"wordCount: {wordCount}\")\n",
    "print(f\"Newlines: {newline_count}\")\n",
    "print(f\"Spaces: {space_count}\")\n",
    "print(f\"Tabs: {tab_count}\")\n",
    "allCount = wordCount+newline_count+space_count+tab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1693.6553771798294"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wordCount+newline_count+space_count+tab_count)/dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119709479"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount+newline_count+tab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369350671"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548.9271273254187\n"
     ]
    }
   ],
   "source": [
    "average = allCount/dataset.num_rows\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[218000][\"content\"].count('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1845e+00,  4.5742e+00,  3.0843e+00, -4.4525e-01],\n",
       "        [ 5.6453e-01,  1.2282e+00,  7.9614e-01,  1.9521e+00],\n",
       "        [ 8.9111e-01, -7.5050e-01,  3.8116e-04, -3.5875e-01]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义一个模拟的相似度计算类\n",
    "class SimilarityComputer:\n",
    "    def compute_similarity(self, q_reps, p_reps):\n",
    "        if len(p_reps.size()) == 2:\n",
    "            return torch.matmul(q_reps, p_reps.transpose(0, 1))\n",
    "        return torch.matmul(q_reps, p_reps.transpose(-2, -1))\n",
    "\n",
    "# 实例化这个类\n",
    "sim_computer = SimilarityComputer()\n",
    "\n",
    "# 创建一些示例数据\n",
    "# 假设有3个查询和4个页面/文档，每个表示的维度是5\n",
    "q_reps = torch.randn(3, 5)\n",
    "p_reps = torch.randn(4, 5)\n",
    "\n",
    "# 计算相似性\n",
    "similarity_matrix = sim_computer.compute_similarity(q_reps, p_reps)\n",
    "\n",
    "# 打印相似性矩阵\n",
    "similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7618,  0.5248, -1.4861, -1.7878, -0.3803],\n",
       "        [ 1.3576,  0.3313,  0.5518, -0.7317,  0.1051],\n",
       "        [ 1.0891, -0.6134, -0.0453,  0.6692, -0.1062]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2450, -1.2239,  1.0084, -0.0141,  0.6720],\n",
       "        [ 0.1995,  0.1531, -0.1556, -1.7364, -2.6459],\n",
       "        [ 0.2211, -1.2953, -0.4167, -1.6134, -0.2422],\n",
       "        [ 0.6901,  2.3909,  1.1986,  0.4577, -0.9828]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def dense_score(self, q_reps, p_reps):\n",
    "    scores = self.compute_similarity(q_reps, p_reps) / self.temperature\n",
    "    scores = scores.view(q_reps.size(0), -1)\n",
    "    return scores\n",
    "\n",
    "def sparse_score(self, q_reps, p_reps):\n",
    "    scores = self.compute_similarity(q_reps, p_reps) / self.temperature\n",
    "    scores = scores.view(q_reps.size(0), -1)\n",
    "    return scores\n",
    "\n",
    "def colbert_score(self, q_reps, p_reps, q_mask: torch.Tensor):\n",
    "    token_scores = torch.einsum('qin,pjn->qipj', q_reps, p_reps)\n",
    "    scores, _ = token_scores.max(-1)\n",
    "    scores = scores.sum(1) / q_mask[:, 1:].sum(-1, keepdim=True)\n",
    "    scores = scores / self.temperature\n",
    "    return scores\n",
    "\n",
    "def compute_loss(self, scores, target):\n",
    "    return self.cross_entropy(scores, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idxs = torch.arange(q_dense_vecs.size(0), device=q_dense_vecs.device, dtype=torch.long)\n",
    "targets = idxs * (p_sparse_vecs.size(0) // q_sparse_vecs.size(0))\n",
    "dense_scores = dense_score(q_dense_vecs, p_dense_vecs)  # B, B * N\n",
    "\n",
    "loss = compute_loss(dense_scores, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Loss: 0.043626248836517334\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cosine_similarity_loss(transformer_features, target_features):\n",
    "    # 计算余弦相似度\n",
    "    similarity = F.cosine_similarity(transformer_features, target_features, dim=-1)\n",
    "    \n",
    "    # 将相似度转换为损失，注意这里我们直接计算1 - similarity作为损失\n",
    "    loss = 1 - similarity\n",
    "    return loss.mean()  # 对所有样本的损失求平均\n",
    "\n",
    "# 创建示例特征向量\n",
    "transformer_features = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]], dtype=torch.float32)\n",
    "target_features = torch.tensor([[0.2, 0.2, 0.2], [0.5, 0.5, 0.5]], dtype=torch.float32)\n",
    "\n",
    "# 计算损失\n",
    "loss = cosine_similarity_loss(transformer_features, target_features)\n",
    "print(\"Cosine Similarity Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Loss: 0.26115649938583374\n"
     ]
    }
   ],
   "source": [
    "# 创建示例特征向量\n",
    "transformer_features = torch.tensor([[0.1, 0.1, 0.3], [0.4, 0.5, 0.4]], dtype=torch.float32)\n",
    "target_features = torch.tensor([[0.9, 0.9, 0.1], [0.6, 0.5, 0.6]], dtype=torch.float32)\n",
    "\n",
    "# 计算损失\n",
    "loss = cosine_similarity_loss(transformer_features, target_features)\n",
    "print(\"Cosine Similarity Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Loss: 0.03723827004432678\n"
     ]
    }
   ],
   "source": [
    "# 创建示例特征向量\n",
    "transformer_features = torch.tensor([[0.1, 0.1, 0.3], [0.4, 0.5, 0.4]], dtype=torch.float32)\n",
    "target_features = torch.tensor([[0.3, 0.4, 0.5], [0.6, 0.7, 0.8]], dtype=torch.float32)\n",
    "\n",
    "# 计算损失\n",
    "loss = cosine_similarity_loss(transformer_features, target_features)\n",
    "print(\"Cosine Similarity Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最短的字符长度（包括空格和制表符）为: 1\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# 加载数据集\n",
    "CACHE_DIR = \"/home/liuchao/shushanfu/LMOps/data/huggingface_cache\"\n",
    "\n",
    "# only get one packet\n",
    "dataset = datasets.load_dataset('bigcode/starcoderdata', split='train',data_files=\"python/train-00000-of-00059.parquet\",trust_remote_code=True,cache_dir=CACHE_DIR)\n",
    "\n",
    "# 初始化最小长度为一个较大的数\n",
    "min_length = float('inf')\n",
    "total_min_256 = 0\n",
    "# 遍历数据集中的每个样本\n",
    "for example in dataset:\n",
    "    wordCount = 0\n",
    "    newline_count = 0  # 回车 \\n\n",
    "    space_count = 0    # 空格\n",
    "    tab_count = 0      # 制表符 \\t\n",
    "    content = example['content']\n",
    "    # 拆分成单词并更新计数\n",
    "    wordCount += len(content.split())\n",
    "    newline_count += content.count('\\n')\n",
    "    space_count += content.count(' ')\n",
    "    tab_count += content.count('\\t')\n",
    "    # 计算样本字符串长度，包括空格和制表符\n",
    "    allCount = wordCount+newline_count+space_count+tab_count\n",
    "    # 更新最小长度\n",
    "    min_length = min(min_length, allCount)\n",
    "    if min_length<256:\n",
    "        total_min_256+=1\n",
    "\n",
    "# 输出最小长度\n",
    "print(\"最短的字符长度（包括空格和制表符）为:\", min_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_min_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"1,2,0.0.2564546546541432123  45634123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
