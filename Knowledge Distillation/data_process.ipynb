{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'repo': 'apache/spark', 'path': 'python/pyspark/rdd.py', 'func_name': 'RDD.foldByKey', 'original_string': 'def foldByKey(self, zeroValue, func, numPartitions=None, partitionFunc=portable_hash):\\n        \"\"\"\\n        Merge the values for each key using an associative function \"func\"\\n        and a neutral \"zeroValue\" which may be added to the result an\\n        arbitrary number of times, and must not change the result\\n        (e.g., 0 for addition, or 1 for multiplication.).\\n\\n        >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\\n        >>> from operator import add\\n        >>> sorted(rdd.foldByKey(0, add).collect())\\n        [(\\'a\\', 2), (\\'b\\', 1)]\\n        \"\"\"\\n        def createZero():\\n            return copy.deepcopy(zeroValue)\\n\\n        return self.combineByKey(lambda v: func(createZero(), v), func, func, numPartitions,\\n                                 partitionFunc)', 'language': 'python', 'code': 'def foldByKey(self, zeroValue, func, numPartitions=None, partitionFunc=portable_hash):\\n        \"\"\"\\n        Merge the values for each key using an associative function \"func\"\\n        and a neutral \"zeroValue\" which may be added to the result an\\n        arbitrary number of times, and must not change the result\\n        (e.g., 0 for addition, or 1 for multiplication.).\\n\\n        >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\\n        >>> from operator import add\\n        >>> sorted(rdd.foldByKey(0, add).collect())\\n        [(\\'a\\', 2), (\\'b\\', 1)]\\n        \"\"\"\\n        def createZero():\\n            return copy.deepcopy(zeroValue)\\n\\n        return self.combineByKey(lambda v: func(createZero(), v), func, func, numPartitions,\\n                                 partitionFunc)', 'code_tokens': ['def', 'foldByKey', '(', 'self', ',', 'zeroValue', ',', 'func', ',', 'numPartitions', '=', 'None', ',', 'partitionFunc', '=', 'portable_hash', ')', ':', 'def', 'createZero', '(', ')', ':', 'return', 'copy', '.', 'deepcopy', '(', 'zeroValue', ')', 'return', 'self', '.', 'combineByKey', '(', 'lambda', 'v', ':', 'func', '(', 'createZero', '(', ')', ',', 'v', ')', ',', 'func', ',', 'func', ',', 'numPartitions', ',', 'partitionFunc', ')'], 'docstring': 'Merge the values for each key using an associative function \"func\"\\n        and a neutral \"zeroValue\" which may be added to the result an\\n        arbitrary number of times, and must not change the result\\n        (e.g., 0 for addition, or 1 for multiplication.).\\n\\n        >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\\n        >>> from operator import add\\n        >>> sorted(rdd.foldByKey(0, add).collect())\\n        [(\\'a\\', 2), (\\'b\\', 1)]', 'docstring_tokens': ['Merge', 'the', 'values', 'for', 'each', 'key', 'using', 'an', 'associative', 'function', 'func', 'and', 'a', 'neutral', 'zeroValue', 'which', 'may', 'be', 'added', 'to', 'the', 'result', 'an', 'arbitrary', 'number', 'of', 'times', 'and', 'must', 'not', 'change', 'the', 'result', '(', 'e', '.', 'g', '.', '0', 'for', 'addition', 'or', '1', 'for', 'multiplication', '.', ')', '.'], 'sha': '618d6bff71073c8c93501ab7392c3cc579730f0b', 'url': 'https://github.com/apache/spark/blob/618d6bff71073c8c93501ab7392c3cc579730f0b/python/pyspark/rdd.py#L1893-L1909', 'partition': 'train'}\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "target_line_number = 100\n",
    "\n",
    "file = \"python_train_0.jsonl.gz\"\n",
    "path = f\"/home/liuchao/shushanfu/LMOps/data/codeSearchNet/python/final/jsonl/train/{file}\"\n",
    "# 打开gzip文件\n",
    "def get_data(file_name,target_line_number = 100):\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        current_line_number = 0\n",
    "        for line in f:\n",
    "            current_line_number += 1\n",
    "            if current_line_number == target_line_number:\n",
    "                # 解析JSON数据\n",
    "                data = json.loads(line)\n",
    "                return data  # 找到第100行后退出循环\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'repo': 'ageitgey/face_recognition', 'path': 'examples/face_recognition_knn.py', 'func_name': 'train', 'original_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf', 'language': 'python', 'code': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf', 'code_tokens': ['def', 'train', '(', 'train_dir', ',', 'model_save_path', '=', 'None', ',', 'n_neighbors', '=', 'None', ',', 'knn_algo', '=', \"'ball_tree'\", ',', 'verbose', '=', 'False', ')', ':', 'X', '=', '[', ']', 'y', '=', '[', ']', '# Loop through each person in the training set', 'for', 'class_dir', 'in', 'os', '.', 'listdir', '(', 'train_dir', ')', ':', 'if', 'not', 'os', '.', 'path', '.', 'isdir', '(', 'os', '.', 'path', '.', 'join', '(', 'train_dir', ',', 'class_dir', ')', ')', ':', 'continue', '# Loop through each training image for the current person', 'for', 'img_path', 'in', 'image_files_in_folder', '(', 'os', '.', 'path', '.', 'join', '(', 'train_dir', ',', 'class_dir', ')', ')', ':', 'image', '=', 'face_recognition', '.', 'load_image_file', '(', 'img_path', ')', 'face_bounding_boxes', '=', 'face_recognition', '.', 'face_locations', '(', 'image', ')', 'if', 'len', '(', 'face_bounding_boxes', ')', '!=', '1', ':', '# If there are no people (or too many people) in a training image, skip the image.', 'if', 'verbose', ':', 'print', '(', '\"Image {} not suitable for training: {}\"', '.', 'format', '(', 'img_path', ',', '\"Didn\\'t find a face\"', 'if', 'len', '(', 'face_bounding_boxes', ')', '<', '1', 'else', '\"Found more than one face\"', ')', ')', 'else', ':', '# Add face encoding for current image to the training set', 'X', '.', 'append', '(', 'face_recognition', '.', 'face_encodings', '(', 'image', ',', 'known_face_locations', '=', 'face_bounding_boxes', ')', '[', '0', ']', ')', 'y', '.', 'append', '(', 'class_dir', ')', '# Determine how many neighbors to use for weighting in the KNN classifier', 'if', 'n_neighbors', 'is', 'None', ':', 'n_neighbors', '=', 'int', '(', 'round', '(', 'math', '.', 'sqrt', '(', 'len', '(', 'X', ')', ')', ')', ')', 'if', 'verbose', ':', 'print', '(', '\"Chose n_neighbors automatically:\"', ',', 'n_neighbors', ')', '# Create and train the KNN classifier', 'knn_clf', '=', 'neighbors', '.', 'KNeighborsClassifier', '(', 'n_neighbors', '=', 'n_neighbors', ',', 'algorithm', '=', 'knn_algo', ',', 'weights', '=', \"'distance'\", ')', 'knn_clf', '.', 'fit', '(', 'X', ',', 'y', ')', '# Save the trained KNN classifier', 'if', 'model_save_path', 'is', 'not', 'None', ':', 'with', 'open', '(', 'model_save_path', ',', \"'wb'\", ')', 'as', 'f', ':', 'pickle', '.', 'dump', '(', 'knn_clf', ',', 'f', ')', 'return', 'knn_clf'], 'docstring': 'Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.', 'docstring_tokens': ['Trains', 'a', 'k', '-', 'nearest', 'neighbors', 'classifier', 'for', 'face', 'recognition', '.'], 'sha': 'c96b010c02f15e8eeb0f71308c641179ac1f19bb', 'url': 'https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108', 'partition': 'train'}\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(path,1)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
      "    \"\"\"\n",
      "    Trains a k-nearest neighbors classifier for face recognition.\n",
      "\n",
      "    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
      "\n",
      "     (View in source code to see train_dir example tree structure)\n",
      "\n",
      "     Structure:\n",
      "        <train_dir>/\n",
      "        ├── <person1>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   ├── <somename2>.jpeg\n",
      "        │   ├── ...\n",
      "        ├── <person2>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   └── <somename2>.jpeg\n",
      "        └── ...\n",
      "\n",
      "    :param model_save_path: (optional) path to save model on disk\n",
      "    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n",
      "    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
      "    :param verbose: verbosity of training\n",
      "    :return: returns knn classifier that was trained on the given data.\n",
      "    \"\"\"\n",
      "    X = []\n",
      "    y = []\n",
      "\n",
      "    # Loop through each person in the training set\n",
      "    for class_dir in os.listdir(train_dir):\n",
      "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
      "            continue\n",
      "\n",
      "        # Loop through each training image for the current person\n",
      "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
      "            image = face_recognition.load_image_file(img_path)\n",
      "            face_bounding_boxes = face_recognition.face_locations(image)\n",
      "\n",
      "            if len(face_bounding_boxes) != 1:\n",
      "                # If there are no people (or too many people) in a training image, skip the image.\n",
      "                if verbose:\n",
      "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
      "            else:\n",
      "                # Add face encoding for current image to the training set\n",
      "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
      "                y.append(class_dir)\n",
      "\n",
      "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
      "    if n_neighbors is None:\n",
      "        n_neighbors = int(round(math.sqrt(len(X))))\n",
      "        if verbose:\n",
      "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
      "\n",
      "    # Create and train the KNN classifier\n",
      "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
      "    knn_clf.fit(X, y)\n",
      "\n",
      "    # Save the trained KNN classifier\n",
      "    if model_save_path is not None:\n",
      "        with open(model_save_path, 'wb') as f:\n",
      "            pickle.dump(knn_clf, f)\n",
      "\n",
      "    return knn_clf\n"
     ]
    }
   ],
   "source": [
    "print(train_data['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"python_test_0.jsonl.gz\"\n",
    "test_path = f\"/home/liuchao/shushanfu/LMOps/data/codeSearchNet/python/final/jsonl/test/{test_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_data(test_path,105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def clear_dag_task_instances():\n",
      "    \"\"\"\n",
      "    Remove any existing task instances for the perf test DAGs.\n",
      "    \"\"\"\n",
      "    session = settings.Session()\n",
      "    TI = TaskInstance\n",
      "    tis = (\n",
      "        session\n",
      "        .query(TI)\n",
      "        .filter(TI.dag_id.in_(DAG_IDS))\n",
      "        .all()\n",
      "    )\n",
      "    for ti in tis:\n",
      "        logging.info('Deleting TaskInstance :: {}'.format(ti))\n",
      "        session.delete(ti)\n",
      "    session.commit()\n"
     ]
    }
   ],
   "source": [
    "print(test_data['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_code(code):\n",
    "    lines = code.split('\\n')\n",
    "    function, docstring, body = '', '', []\n",
    "    docstring_start = False\n",
    "    for line in lines:\n",
    "        if line.startswith('def '):\n",
    "            function = line\n",
    "        elif '\"\"\"' in line:\n",
    "            if not docstring_start:  # Docstring开始\n",
    "                docstring_start = True\n",
    "                docstring += line.replace('\"\"\"', '').strip() + ' '\n",
    "            else:  # Docstring结束\n",
    "                docstring_start = False\n",
    "                docstring += line.replace('\"\"\"', '').strip()\n",
    "        elif docstring_start:  # 处理多行Docstring\n",
    "            docstring += line.strip() + ' '\n",
    "        else:\n",
    "            body.append(line)\n",
    "\n",
    "    # 将body列表转换回字符串形式\n",
    "    body_text = '\\n'.join(body)\n",
    "    return function, docstring, body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data['code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(os.path.join( \"/home/liuchao/shushanfu/LMOps/data/dolly/raw.jsonl\")) as f:\n",
    "    raw_data = f.readline()\n",
    "    data = json.loads(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topic', 'instruction', 'input', 'output', 'prompt'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'summarization',\n",
       " 'instruction': 'Who were the major players in the Watergate conspiracy?',\n",
       " 'input': \"The Watergate scandal was a major political scandal in the United States involving the administration of President Richard Nixon from 1972 to 1974 that led to Nixon's resignation. The scandal stemmed from the Nixon administration's persistent attempts to cover up its involvement in the June 17, 1972 break-in of the Democratic National Committee headquarters at the Washington, D.C., Watergate Office Building.\",\n",
       " 'output': \"The list begins with the President of the United States, Richard Nixon. John Dean served as the Counsel to the President, and was a lead witness whose testimony blew the case wide open, naming many top presidential aides as being closely involved. H.R. Haldeman, John Ehrlichman, and John Mitchell were all senior members of the administration who resigned in disgraced and were convicted. Howard Hunt and G. Gordon Liddy played major roles in the Watergate break-in. \\n\\nA major figure in the conspiracy was Daniel Ellsberg, but not for any wrongdoing. Rather, he was a target of the Nixon White House, and an attempted burglary of his psychiatrist's office was just one of the illegal acts that the White House covered up.\",\n",
       " 'prompt': \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWho were the major players in the Watergate conspiracy?\\n\\n### Input:\\nThe Watergate scandal was a major political scandal in the United States involving the administration of President Richard Nixon from 1972 to 1974 that led to Nixon's resignation. The scandal stemmed from the Nixon administration's persistent attempts to cover up its involvement in the June 17, 1972 break-in of the Democratic National Committee headquarters at the Washington, D.C., Watergate Office Building.\\n\\n### Response:\\n\"}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(file=os.path.join( \"/home/liuchao/shushanfu/LMOps/data/codesearchnet/raw.jsonl\")) as f:\n",
    "    code_data = f.readline()\n",
    "    code_data = json.loads(code_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'def get_vid_from_url(url):',\n",
       " 'instruction': 'Extracts video ID from URL. ',\n",
       " 'output': \"        return match1(url, r'youtu\\\\.be/([^?/]+)') or \\\\\\n          match1(url, r'youtube\\\\.com/embed/([^/?]+)') or \\\\\\n          match1(url, r'youtube\\\\.com/v/([^/?]+)') or \\\\\\n          match1(url, r'youtube\\\\.com/watch/([^/?]+)') or \\\\\\n          parse_query_param(url, 'v') or \\\\\\n          parse_query_param(parse_query_param(url, 'u'), 'v')\"}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test = {\"instruction\": \"\", \"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n\\n\\n### Input:\\ndef display_fence(self):\\n\\n### Response:\\n\", \"input\": \"def display_fence(self):\", \"output\": \"        '''display the fence'''\\n        from MAVProxy.modules.mavproxy_map import mp_slipmap\\n        self.fence_change_time = self.module('fence').fenceloader.last_change\\n        points = self.module('fence').fenceloader.polygon()\\n        self.mpstate.map.add_object(mp_slipmap.SlipClearLayer('Fence'))\\n        if len(points) > 1:\\n            popup = MPMenuSubMenu('Popup',\\n                                  items=[MPMenuItem('FencePoint Remove', returnkey='popupFenceRemove'),\\n                                         MPMenuItem('FencePoint Move', returnkey='popupFenceMove')])\\n            self.mpstate.map.add_object(mp_slipmap.SlipPolygon('Fence', points, layer=1,\\n                                                               linewidth=2, colour=(0,255,0), popup_menu=popup))\"}\n",
    "test = json.loads(json.dumps(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def display_fence(self):\n"
     ]
    }
   ],
   "source": [
    "print(test[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        '''display the fence'''\n",
      "        from MAVProxy.modules.mavproxy_map import mp_slipmap\n",
      "        self.fence_change_time = self.module('fence').fenceloader.last_change\n",
      "        points = self.module('fence').fenceloader.polygon()\n",
      "        self.mpstate.map.add_object(mp_slipmap.SlipClearLayer('Fence'))\n",
      "        if len(points) > 1:\n",
      "            popup = MPMenuSubMenu('Popup',\n",
      "                                  items=[MPMenuItem('FencePoint Remove', returnkey='popupFenceRemove'),\n",
      "                                         MPMenuItem('FencePoint Move', returnkey='popupFenceMove')])\n",
      "            self.mpstate.map.add_object(mp_slipmap.SlipPolygon('Fence', points, layer=1,\n",
      "                                                               linewidth=2, colour=(0,255,0), popup_menu=popup))\n"
     ]
    }
   ],
   "source": [
    "print(test[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test[\"input\"] + \"\\n\" + test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def display_fence(self):\n",
      "        '''display the fence'''\n",
      "        from MAVProxy.modules.mavproxy_map import mp_slipmap\n",
      "        self.fence_change_time = self.module('fence').fenceloader.last_change\n",
      "        points = self.module('fence').fenceloader.polygon()\n",
      "        self.mpstate.map.add_object(mp_slipmap.SlipClearLayer('Fence'))\n",
      "        if len(points) > 1:\n",
      "            popup = MPMenuSubMenu('Popup',\n",
      "                                  items=[MPMenuItem('FencePoint Remove', returnkey='popupFenceRemove'),\n",
      "                                         MPMenuItem('FencePoint Move', returnkey='popupFenceMove')])\n",
      "            self.mpstate.map.add_object(mp_slipmap.SlipPolygon('Fence', points, layer=1,\n",
      "                                                               linewidth=2, colour=(0,255,0), popup_menu=popup))\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "function, docstring, body_text = parse_code(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def display_fence(self):'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_code_v2(code):\n",
    "    lines = code.split('\\n')\n",
    "    function, docstring, body = '', '', []\n",
    "    in_docstring = False\n",
    "    docstring_delimiter = None  # 用于标记当前文档字符串使用的是三个单引号还是双引号\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # 检测函数定义\n",
    "        if stripped_line.startswith('def ') and not in_docstring:\n",
    "            function = stripped_line\n",
    "        # 检测文档字符串的开始或结束\n",
    "        elif (stripped_line.startswith('\"\"\"') or stripped_line.startswith(\"'''\")) and not in_docstring:\n",
    "            # 文档字符串开始\n",
    "            in_docstring = True\n",
    "            docstring_delimiter = stripped_line[:3]  # 记录是使用的哪种引号\n",
    "            docstring += stripped_line[3:] + ' '  # 去掉前面的三个引号\n",
    "            # 如果文档字符串在一行内结束\n",
    "            if stripped_line.endswith(docstring_delimiter) and len(stripped_line) > 3:\n",
    "                in_docstring = False\n",
    "                docstring = docstring[:-3].strip()  # 去掉末尾的三个引号\n",
    "        elif stripped_line.endswith(docstring_delimiter) and in_docstring:\n",
    "            # 文档字符串结束\n",
    "            in_docstring = False\n",
    "            docstring += stripped_line[:-3]  # 去掉末尾的三个引号\n",
    "        elif in_docstring:\n",
    "            # 处理文档字符串内的行\n",
    "            docstring += stripped_line + ' '\n",
    "        else:\n",
    "            # 处理函数体\n",
    "            body.append(line)\n",
    "\n",
    "    body_text = '\\n'.join(body).strip()\n",
    "    return function, docstring.strip(), body_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "function, docstring, body_text = parse_code_v2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from MAVProxy.modules.mavproxy_map import mp_slipmap\n",
      "        self.fence_change_time = self.module('fence').fenceloader.last_change\n",
      "        points = self.module('fence').fenceloader.polygon()\n",
      "        self.mpstate.map.add_object(mp_slipmap.SlipClearLayer('Fence'))\n",
      "        if len(points) > 1:\n",
      "            popup = MPMenuSubMenu('Popup',\n",
      "                                  items=[MPMenuItem('FencePoint Remove', returnkey='popupFenceRemove'),\n",
      "                                         MPMenuItem('FencePoint Move', returnkey='popupFenceMove')])\n",
      "            self.mpstate.map.add_object(mp_slipmap.SlipPolygon('Fence', points, layer=1,\n",
      "                                                               linewidth=2, colour=(0,255,0), popup_menu=popup))\n"
     ]
    }
   ],
   "source": [
    "print(body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display the fence'\n"
     ]
    }
   ],
   "source": [
    "print(docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import load_checkpoint_and_dispatch, init_empty_weights\n",
    "import torch.distributed as dist\n",
    "from torch.distributed import get_rank\n",
    "from utils import get_tokenizer, get_model, parallel_model_map\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    ParallelOPTForCausalLM,\n",
    "    ParallelLlamaForCausalLM,\n",
    "    ParallelGPTJForCausalLM,\n",
    "    ParallelGPT2LMHeadModel,\n",
    "    ParallelMistralForCausalLM,\n",
    "    ParallelQWenLMHeadModel,\n",
    "    mpu,)\n",
    "\n",
    "parallel_model_map = {\n",
    "    \"opt\": ParallelOPTForCausalLM,\n",
    "    \"gptj\": ParallelGPTJForCausalLM,\n",
    "    \"gpt2\": ParallelGPT2LMHeadModel,\n",
    "    \"llama\": ParallelLlamaForCausalLM,\n",
    "    \"llama2\": ParallelLlamaForCausalLM,\n",
    "    \"mistral\": ParallelMistralForCausalLM,\n",
    "    \"qwen\": ParallelQWenLMHeadModel,\n",
    "}\n",
    "import random\n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['MASTER_ADDR'] = 'localhost' # 假设使用单机多卡\n",
    "os.environ['MASTER_PORT'] = '12355' # 使用一个未被占用的端口\n",
    "\n",
    "# 初始化进程组\n",
    "dist.init_process_group(backend='nccl', init_method='env://', world_size=2, rank=0)\n",
    "\n",
    "# Initialize\n",
    "def set_random_seed(seed = 20, mp=False):\n",
    "    \"\"\"Set random seed for reproducability.\"\"\"\n",
    "    seed = dist.get_rank() + seed\n",
    "    if seed is not None and seed > 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if mp:\n",
    "            mpu.model_parallel_cuda_manual_seed(seed)\n",
    "\n",
    "def initialize(model_parallel:False,model_parallel_size=2):\n",
    "    # init bmt\n",
    "    if model_parallel:\n",
    "        assert dist.get_world_size() % model_parallel_size == 0 \n",
    "        mpu.initialize_model_parallel(model_parallel_size)\n",
    "    set_random_seed(20, model_parallel)\n",
    "\n",
    "initialize(True,2)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,2'\n",
    "ckpt_dir = \"/home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1\"\n",
    "tokenizer_path = \"/home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(ckpt_dir)\n",
    "config.is_model_parallel = True\n",
    "model = ParallelLlamaForCausalLM(config).half()\n",
    "\n",
    "def load_parallel(model, load_dir):\n",
    "    mp_rank = mpu.get_model_parallel_rank()\n",
    "    assert mpu.get_model_parallel_world_size() != 1\n",
    "    checkpoint_name = os.path.join(load_dir, f\"mp{mpu.get_model_parallel_world_size()}\", f\"pytorch_model_{mp_rank}.bin\")\n",
    "    assert os.path.exists(checkpoint_name), f\"{checkpoint_name} does not exist.\"\n",
    "    model = load_checkpoint_and_dispatch(model=model, checkpoint=checkpoint_name, device_map={\"\": torch.cuda.current_device()}, dtype=torch.float16)\n",
    "    dist.barrier()\n",
    "    print(f\"Rank {get_rank()}: {checkpoint_name} loaded.\")\n",
    "\n",
    "load_parallel(model, ckpt_dir)\n",
    "device = torch.cuda.current_device()\n",
    "model = model.to(device)\n",
    "# model_path = ckpt_dir\n",
    "# tokenizer_path = ckpt_dir if tokenizer_path is None else tokenizer_path\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_path,trust_remote_code=False,code_revision=None)\n",
    "# model = LlamaForCausalLM.from_pretrained(\n",
    "#     model_path, device_map=\"auto\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No ':' found when decoding object value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/liuchao/shushanfu/LMOps/data/evaluate/1.1B_512_8_1000.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdllm/lib/python3.10/site-packages/pandas/io/json/_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdllm/lib/python3.10/site-packages/pandas/io/json/_json.py:1023\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         data \u001b[38;5;241m=\u001b[39m ensure_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m   1022\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdllm/lib/python3.10/site-packages/pandas/io/json/_json.py:1051\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/kdllm/lib/python3.10/site-packages/pandas/io/json/_json.py:1187\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdllm/lib/python3.10/site-packages/pandas/io/json/_json.py:1403\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1399\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1403\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m     )\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1406\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1407\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1409\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: No ':' found when decoding object value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_json(\"/home/liuchao/shushanfu/LMOps/data/evaluate/1.1B_512_8_1000.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>for i, v in enumerate(numbers):\\n        f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>result = []\\n    paren_stack = []\\n\\n    f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td># Decimal\\n    decimal = number - int(numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>if len(operations) != 0:\\n        for op i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td># Calculate the average value within the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>HumanEval/163</td>\n",
       "      <td>result = []\\n    while a &lt; b:\\n        a_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>HumanEval/160</td>\n",
       "      <td>operator_keys = operator.keys()\\n    opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>HumanEval/161</td>\n",
       "      <td>if s == \"\" or s==None:\\n            return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>HumanEval/162</td>\n",
       "      <td>if len(text) == 0:\\n        return None\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>HumanEval/163</td>\n",
       "      <td>result = []\\n    while a &lt; b:\\n        a_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           task_id                                         completion\n",
       "0      HumanEval/0      for i, v in enumerate(numbers):\\n        f...\n",
       "1      HumanEval/1      result = []\\n    paren_stack = []\\n\\n    f...\n",
       "2      HumanEval/2      # Decimal\\n    decimal = number - int(numb...\n",
       "3      HumanEval/3      if len(operations) != 0:\\n        for op i...\n",
       "4      HumanEval/4      # Calculate the average value within the g...\n",
       "..             ...                                                ...\n",
       "323  HumanEval/163      result = []\\n    while a < b:\\n        a_d...\n",
       "324  HumanEval/160      operator_keys = operator.keys()\\n    opera...\n",
       "325  HumanEval/161      if s == \"\" or s==None:\\n            return...\n",
       "326  HumanEval/162      if len(text) == 0:\\n        return None\\n ...\n",
       "327  HumanEval/163      result = []\\n    while a < b:\\n        a_d...\n",
       "\n",
       "[328 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic line at 132: Expecting ',' delimiter: line 2 column 1 (char 2759)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 将这个路径替换为你的文件路径\n",
    "file_path = '/home/liuchao/shushanfu/LMOps/data/evaluate/1.1B_512_8_500.jsonl'\n",
    "\n",
    "def find_problematic_lines(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        line_number = 0\n",
    "        for line in file:\n",
    "            line_number += 1\n",
    "            try:\n",
    "                # 尝试解析每一行\n",
    "                json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # 打印出问题行的行号和错误信息\n",
    "                print(f'Problematic line at {line_number}: {e}')\n",
    "\n",
    "find_problematic_lines(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1/mp2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(teacher_model_path)\n\u001b[1;32m      8\u001b[0m config\u001b[38;5;241m.\u001b[39mis_model_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_model_parallel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LMOps/transformers/src/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/LMOps/transformers/src/transformers/modeling_utils.py:2992\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2987\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2988\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2989\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2990\u001b[0m         )\n\u001b[1;32m   2991\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2993\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2994\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2995\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2996\u001b[0m         )\n\u001b[1;32m   2997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[1;32m   2998\u001b[0m     archive_file \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n",
      "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1/mp2."
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig,AutoModelForCausalLM\n",
    "import torch\n",
    "teacher_model_path = \"/home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1\"\n",
    "teacher_model_parallel_path = \"/home/liuchao/shushanfu/LMOps/checkpoints/TinyLlama-1.1B-python-v0.1/mp2\"\n",
    "device = torch.cuda.current_device()\n",
    "config = AutoConfig.from_pretrained(teacher_model_path)\n",
    "\n",
    "config.is_model_parallel = False\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    teacher_model_parallel_path, \n",
    "    config=config, \n",
    "    device_map={\"\": device}, \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tetst(num,test):\n",
    "    print(1)\n",
    "\n",
    "def tetst(num,test,ee):\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "tetst(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test1 = torch.zeros([4,6,3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3200])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    " \n",
    "# 假设 log_prob 和 target 是你的两个概率分布，它们应该是相同形状的张量\n",
    "log_prob = torch.randn(3, 5)  # 示例：3个样本，每个样本有5个概率值\n",
    "target = torch.rand(3, 5)     # 同样形状的另一个概率分布作为比较基准\n",
    " \n",
    "# 使用 torch.nn.functional.kl_div 计算KL散度\n",
    "kl_div = F.kl_div(log_prob.log(), target, reduction='sum')  # reduction参数指定了如何对结果进行聚合（例如求和或平均）\n",
    "print(kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9632)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2664041/2374150938.py:5: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_a =F.log_softmax(a)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    " \n",
    "a = torch.tensor([[0,0,1.1,2,0,1000,0],[0,0,1,2,0,1000,0]])\n",
    "log_a =F.log_softmax(a)\n",
    " \n",
    "b = torch.tensor([[0,0,1.1,2,0,7,0],[0,0,1,2,0,10,0]])\n",
    "softmax_b =F.softmax(b,dim=-1)\n",
    " \n",
    "kl_mean = F.kl_div(log_a, softmax_b, reduction='mean')\n",
    "print(kl_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"task_id\": \"HumanEval/135\", \"completion\": \"Here's the Python script for the given problem:\\n\\ndef can_arrange(arr):\\n    \\\"\\\"\\\"\\n    This function takes an array as input and returns the largest index of an element which is not greater than or equal to the element immediately preceding it.\\n    If no such element exists, it returns -1.\\n    \\\"\\\"\\\"\\n    n = len(arr)\\n    for i in range(n-1):\\n        if arr[i] >= arr[i+1]:\\n            return i\\n    return -1\\n\\n# Test cases\\nprint(can_arrange([1,2,4,3,5])) # Output: 3\\nprint(can_arrange([1,2,3])) # Output: -1 \"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "test['completion'] = re.sub(r\"^(Here's.*)\", \"\", test['completion'], flags=re.MULTILINE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/135',\n",
       " 'completion': '\\n\\ndef can_arrange(arr):\\n    \"\"\"\\n    This function takes an array as input and returns the largest index of an element which is not greater than or equal to the element immediately preceding it.\\n    If no such element exists, it returns -1.\\n    \"\"\"\\n    n = len(arr)\\n    for i in range(n-1):\\n        if arr[i] >= arr[i+1]:\\n            return i\\n    return -1\\n\\n# Test cases\\nprint(can_arrange([1,2,4,3,5])) # Output: 3\\nprint(can_arrange([1,2,3])) # Output: -1 '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1500,\n",
       " 2000,\n",
       " 2500,\n",
       " 3000,\n",
       " 3500,\n",
       " 4000,\n",
       " 4500,\n",
       " 5000,\n",
       " 5500,\n",
       " 6000,\n",
       " 6500,\n",
       " 7000,\n",
       " 7500,\n",
       " 8000,\n",
       " 8500,\n",
       " 9000,\n",
       " 9500,\n",
       " 10000]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1500,10500,500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"\"\"    # If the list is empty, just return nothing\\n    if len(lst) == 0:\\n        return []\\n    # Sort by rows in ascending order\\n    lst = sorted(lst, key=lambda x: x[0])\\n    # If a list of coords is non-empty, sort by rows in descending order\\n    if len(lst) > 0:\\n        lst = sorted(lst, key=lambda x: x[1])\\n        for i, row in enumerate(lst):\\n            # If the row is not in the list, just return it\\n            if i >= len(lst) - 1:\\n                return []\\n            # Otherwise, add the row to the list\\n            yield (row[0], row[1])\\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    # If the list is empty, just return nothing\n",
      "    if len(lst) == 0:\n",
      "        return []\n",
      "    # Sort by rows in ascending order\n",
      "    lst = sorted(lst, key=lambda x: x[0])\n",
      "    # If a list of coords is non-empty, sort by rows in descending order\n",
      "    if len(lst) > 0:\n",
      "        lst = sorted(lst, key=lambda x: x[1])\n",
      "        for i, row in enumerate(lst):\n",
      "            # If the row is not in the list, just return it\n",
      "            if i >= len(lst) - 1:\n",
      "                return []\n",
      "            # Otherwise, add the row to the list\n",
      "            yield (row[0], row[1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(lst, x):\n",
    "        # If the list is empty, just return nothing\n",
    "    if len(lst) == 0:\n",
    "        return []\n",
    "    # Sort by rows in ascending order\n",
    "    lst = sorted(lst, key=lambda x: x[0])\n",
    "    # If a list of coords is non-empty, sort by rows in descending order\n",
    "    if len(lst) > 0:\n",
    "        lst = sorted(lst, key=lambda x: x[1])\n",
    "        for i, row in enumerate(lst):\n",
    "            # If the row is not in the list, just return it\n",
    "            if i >= len(lst) - 1:\n",
    "                return []\n",
    "            # Otherwise, add the row to the list\n",
    "            yield (row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_row([      [1,2,3,4,5,6],      [1,2,3,4,1,6],      [1,2,3,4,5,1]    ], 1) == [(0, 0), (1, 4), (1, 0), (2, 5), (2, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this function prints hello world\n",
      "# this function takes a string as input\n",
      "# it returns the string with the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the first letter of the string\n",
      "# the first letter of the string is the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/liuchao/shushanfu/LMOps/results/WizardCoder/train/distillcodecraft_alpaca_star/org_org/MP1/bs4-lr5e-06-G4-N1-NN1-lm1-len512/pe4_rs0.5_nr256_ln_sr_tm0.2/5500\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/liuchao/shushanfu/LMOps/results/WizardCoder/train/distillcodecraft_alpaca_star/org_org/MP1/bs4-lr5e-06-G4-N1-NN1-lm1-len512/pe4_rs0.5_nr256_ln_sr_tm0.2/5500\")\n",
    "inputs = tokenizer(\"# this function prints hello world\", return_tensors=\"pt\")\n",
    "sample = model.generate(**inputs, max_length=128)\n",
    "print(tokenizer.decode(sample[0], truncate_before_pattern=[r\"\\n\\n^#\", \"^'''\", \"\\n\\n\\n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "human_eval_path = \"/home/liuchao/shushanfu/LMOps/data/HumanEval.jsonl\"\n",
    "dataframe = pd.read_json(human_eval_path,lines=True)\n",
    "prompts = dataframe['prompt'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def below_zero(operations: List[int]) -> bool:\n",
      "    \"\"\" You're given a list of deposit and withdrawal operations on a bank account that starts with\n",
      "    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n",
      "    at that point function should return True. Otherwise it should return False.\n",
      "    >>> below_zero([1, 2, 3])\n",
      "    False\n",
      "    >>> below_zero([1, 2, -4, 5])\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def set_random_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_random_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input):\n",
    "    INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "Create a Python script for this problem:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    return INSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intpus2 = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Rewrite this JavaScript function to use ES6 syntax.\n",
    "\n",
    "### input\n",
    "function doubleValue(x) {\\n  return x * 2;\\n}\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "intpus2 = \"\"\"\n",
    "Write a reusuable function in Python that takes two string variables and returns the longest string.\n",
    "write your response here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intpus2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "intpus2 = \"\"\"\n",
    "You're given a list of deposit and withdrawal operations on a bank account that starts with\n",
    "    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n",
    "    at that point function should return True. Otherwise it should return False.\n",
    "\n",
    "from typing import List\n",
    "def below_zero(operations: List[int]) -> bool:\n",
    "    \\\"\\\"\\\"\n",
    "    >>> below_zero([1, 2, 3])\n",
    "    False\n",
    "    >>> below_zero([1, 2, -4, 5])\n",
    "    True\n",
    "    \\\"\\\"\\\"\n",
    "    # write your code here\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a reusuable function in Python that takes two string variables and returns the longest string.\n",
      "write your response here.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def longest_string(str1, str2):\n",
      "    if len(str1) > len(str2):\n",
      "        return str1\n",
      "    else:\n",
      "        return str2\n",
      "\n",
      "print longest_string(\"abc\", \"abc\")\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "gen_prompt = \"Please complete the following Python code without providing any additional tasks such as testing or explanations\\n\"\n",
    "end_prompt = \"    # write your code here\"\n",
    "inputs = intpus2\n",
    "# inputs = intpus2\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
    "generation_config = GenerationConfig(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample= False,\n",
    "    # temperature=0.7,\n",
    "    max_length= 512,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # top_p=0.8\n",
    ")\n",
    "sample = model.generate(**inputs,generation_config = generation_config)\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/codegen-6B-mono\")\n",
    "model_2 = AutoModelForCausalLM.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/codegen-6B-mono\",device=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a reusuable function in Python that takes two string variables and returns the longest string.\n",
      "write your response here.\n",
      "\"\"\"\n",
      "\n",
      "def longest_string(str1, str2):\n",
      "    if len(str1) > len(str2):\n",
      "        return str1\n",
      "    elif len(str1) < len(str2):\n",
      "        return str2\n",
      "    else:\n",
      "        return str1\n",
      "\n",
      "print longest_string(\"abc\", \"def\")\n",
      "print longest_string(\"abc\", \"defgh\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"defghi\")\n",
      "print longest_string(\"abc\", \"\n"
     ]
    }
   ],
   "source": [
    "inputs_2 = tokenizer(intpus2, return_tensors=\"pt\")\n",
    "generation_config = GenerationConfig(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample= False,\n",
    "    # temperature=0.7,\n",
    "    max_length= 512,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # top_p=0.8\n",
    ")\n",
    "sample_2 = model_2.generate(**inputs,generation_config = generation_config)\n",
    "print(tokenizer_2.decode(sample_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate a program to merge two sorted arrays.arr1 = [4, 8, 10, 15]\n",
      "arr2 = [3, 6, 9, 12]\n",
      "write your response here.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def merge(arr1, arr2):\n",
      "    arr3 = []\n",
      "    i = 0\n",
      "    j = 0\n",
      "    while i < len(arr1) and j < len(arr2):\n",
      "        if arr1[i] < arr2[j]:\n",
      "            arr3.append(arr1[i])\n",
      "            i += 1\n",
      "        else:\n",
      "            arr3.append(arr2[j])\n",
      "            j += 1\n",
      "    while i < len(arr1):\n",
      "        arr3.append(arr1[i])\n",
      "        i += 1\n",
      "    while j < len(arr2):\n",
      "        arr3.append(arr2[j])\n",
      "        j += 1\n",
      "    return arr3\n",
      "\n",
      "arr1 = [4, 8, 10, 15]\n",
      "arr2 = [3, 6, 9, 12]\n",
      "print merge(arr1, arr2)\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_2.decode(sample_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198,  8645,   378,   257,  1430,   284, 20121,   734, 23243, 26515,\n",
       "            13,  3258,    16,   796,   685,    19,    11,   807,    11,   838,\n",
       "            11,  1315,    60,   198,  3258,    17,   796,   685,    18,   837,\n",
       "           718,    11,   860,    11,  1105,    60,   198, 13564,   534,  2882,\n",
       "           994,    13,   198, 37811,   198,   198,  4299, 20121,     7,  3258,\n",
       "            16,    11,  5240,    17,  2599,   198, 50284, 37811,   198, 50284,\n",
       "         13102,   469,   734, 23243, 26515,    13,   198, 50284, 37811,   198,\n",
       "         50284,  3258,    16,    13, 30619,  3419,   198, 50284,  3258,    17,\n",
       "            13, 30619,  3419,   198, 50284,    72,   796,   657,   198, 50284,\n",
       "            73,   796,   657,   198, 50284,    74,   796,   657,   198, 50284,\n",
       "          4514,  1312,  1279, 18896,     7,  3258,    16,     8,   290,   474,\n",
       "          1279, 18896,     7,  3258,    17,  2599,   198, 50280,   361,  5240,\n",
       "            16,    58,    72,    60,  1279,  5240,    17,    58,    73,  5974,\n",
       "           198, 50276,  3258,    16,    58,    74,    60,   796,  5240,    16,\n",
       "            58,    72,    60,   198, 50276,    72, 15853,   352,   198, 50276,\n",
       "            74, 15853,   352,   198, 50280, 17772,    25,   198, 50276,  3258,\n",
       "            16,    58,    74,    60,   796,  5240,    17,    58,    73,    60,\n",
       "           198, 50276,    73, 15853,   352,   198, 50276,    74, 15853,   352,\n",
       "           198, 50284,  4514,  1312,  1279, 18896,     7,  3258,    16,  2599,\n",
       "           198, 50280,  3258,    16,    58,    74,    60,   796,  5240,    16,\n",
       "            58,    72,    60,   198, 50280,    72, 15853,   352,   198, 50280,\n",
       "            74, 15853,   352,   198, 50284,  4514,   474,  1279, 18896,     7,\n",
       "          3258,    17,  2599,   198, 50280,  3258,    17,    58,    74,    60,\n",
       "           796,  5240,    17,    58,    73,    60,   198, 50280,    73, 15853,\n",
       "           352,   198, 50280,    74, 15853,   352,   198, 50284,  7783,  5240,\n",
       "            16,   198,   198,   361, 11593,  3672,   834,  6624,   366,   834,\n",
       "         12417,   834,  1298,   198, 50284,  3258,    16,   796,   685,    19,\n",
       "            11,   807,    11,   838,    11,  1315,    60,   198, 50284,  3258,\n",
       "            17,   796,   685,    18,   837,   718,    11,   860,    11,  1105,\n",
       "            60,   198, 50284,  4798,     7,   647,   469,     7,  3258,    16,\n",
       "            11,  5240,    17,  4008,   198, 50256]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_output = model(sample,return_dict=True)\n",
    "teacher_logit = teacher_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(teacher_logit, dim=-1)\n",
    "# probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n",
    "probs_sort, _ = torch.sort(probs, dim=-1, descending=True)\n",
    "probs_sum = torch.cumsum(probs_sort, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1839, 0.3657, 0.4422,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.7804, 0.8790, 0.9202,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.2279, 0.3587, 0.3893,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.7056, 0.8837, 0.9913,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.9151, 0.9797, 0.9912,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.3236, 0.4989, 0.6128,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "       grad_fn=<CumsumBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_2 = probs_sum[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_test = tokenizer.decode(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a reusuable function in Python that takes two string variables and returns the longest string.\n",
      "write your response here.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def longest_string(str1, str2):\n",
      "    if len(str1) > len(str2):\n",
      "        return str1\n",
      "    else:\n",
      "        return str2\n",
      "\n",
      "print longest_string(\"abc\", \"abc\")\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(wc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    words = text.split()  # 通过空格分割字符串\n",
    "    return len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(wc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Confidence(Automodel,intput,sample):\n",
    "    '''\n",
    "    Automodel : model\n",
    "    input->str: the prompt\n",
    "    sample : model_2.generate\n",
    "    '''\n",
    "    output = tokenizer.decode(sample[0])[len(intput):]\n",
    "    output = tokenizer(output, return_tensors=\"pt\")\n",
    "    output = Automodel(**output,return_dict=True)\n",
    "    logit = output.logits\n",
    "    probs = torch.softmax(logit, dim=-1)\n",
    "    # probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n",
    "    probs_sort, _ = torch.sort(probs, dim=-1, descending=True)\n",
    "    probs_sum = torch.cumsum(probs_sort, dim=-1)\n",
    "    return probs_sum[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(sample[0])[len(intpus2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"\"\"\\n\\ndef longest_string(str1, str2):\\n    if len(str1) > len(str2):\\n        return str1\\n    else:\\n        return str2\\n\\nprint longest_string(\"abc\", \"abc\")\\n<|endoftext|>'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(output, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  198, 37811,   198,   198,  4299, 14069,    62,  8841,     7,  2536,\n",
       "            16,    11,   965,    17,  2599,   198, 50284,   361, 18896,     7,\n",
       "          2536,    16,     8,  1875, 18896,     7,  2536,    17,  2599,   198,\n",
       "         50280,  7783,   965,    16,   198, 50284, 17772,    25,   198, 50280,\n",
       "          7783,   965,    17,   198,   198,  4798, 14069,    62,  8841,  7203,\n",
       "         39305,  1600,   366, 39305,  4943,   198, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198, 16594,   257,   302,   385,  7153,  2163,   287, 11361,   326,\n",
       "          2753,   734,  4731,  9633,   290,  5860,   262, 14069,  4731,    13,\n",
       "           198, 13564,   534,  2882,   994,    13,   198,   198, 37811,   198,\n",
       "           198,  4299, 14069,    62,  8841,     7,  2536,    16,    11,   965,\n",
       "            17,  2599,   198, 50284,   361, 18896,     7,  2536,    16,     8,\n",
       "          1875, 18896,     7,  2536,    17,  2599,   198, 50280,  7783,   965,\n",
       "            16,   198, 50284, 17772,    25,   198, 50280,  7783,   965,    17,\n",
       "           198,   198,  4798, 14069,    62,  8841,  7203, 39305,  1600,   366,\n",
       "         39305,  4943,   198, 50256]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = get_Confidence(model,intpus2,sample)\n",
    "out_2 = get_Confidence(model_2,intpus2,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1839, 0.6051, 0.1487, 0.2740, 0.1000, 0.7021, 0.1571, 0.6636, 0.2951,\n",
       "        0.3452, 0.8613, 0.8232, 0.9990, 0.8704, 0.9306, 0.8190, 0.3299, 0.6535,\n",
       "        0.9986, 0.9963, 0.9793, 0.9881, 0.3680, 0.9680, 0.9991, 0.9990, 0.9996,\n",
       "        0.9930, 0.9760, 0.9923, 0.6964, 0.7668, 0.9028, 0.8611, 0.9949, 0.5585,\n",
       "        0.9973, 0.9919, 0.9987, 0.9734, 0.9965, 0.9949, 0.6626, 0.8026, 0.3562,\n",
       "        0.6183, 0.9992, 0.9976, 0.4983, 0.1250, 0.4074, 0.9921, 0.2382, 0.8052,\n",
       "        0.7312, 0.4999, 0.3236], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1917, 0.5889, 0.0997, 0.2799, 0.0662, 0.4673, 0.1874, 0.7261, 0.2158,\n",
       "        0.3148, 0.9660, 0.8240, 0.9997, 0.8200, 0.9364, 0.7369, 0.3471, 0.7788,\n",
       "        0.9991, 0.9972, 0.9777, 0.9971, 0.5941, 0.9967, 0.9989, 0.9997, 0.9991,\n",
       "        0.9895, 0.9838, 0.9912, 0.6885, 0.9056, 0.9865, 0.9358, 0.9975, 0.4307,\n",
       "        0.9987, 0.9890, 0.9982, 0.9985, 0.9984, 0.9962, 0.7706, 0.8733, 0.3084,\n",
       "        0.5516, 0.9999, 0.9995, 0.5291, 0.0508, 0.5450, 0.9866, 0.1975, 0.3789,\n",
       "        0.7702, 0.6851, 0.3254], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1917, 0.8217, 0.6922, 0.3398, 0.4984, 0.7050, 0.3431, 0.2471, 0.4454,\n",
       "        0.1962, 0.5626, 0.2451, 0.4199, 0.4649, 0.3734, 0.3185, 0.1109, 0.4481,\n",
       "        0.5961, 0.6097, 0.3225, 0.8275, 0.4264, 0.2696, 0.3944, 0.8348, 0.3085,\n",
       "        0.2223, 0.8446, 0.7153, 0.5465, 0.5176, 0.5041, 0.7368, 0.9220, 0.2816,\n",
       "        0.9149, 0.9901, 0.7862, 0.9996, 0.9927, 0.9657, 0.7545, 0.6407, 0.8667,\n",
       "        0.9989, 0.9981, 0.9910, 0.9984, 0.6198, 0.9965, 0.9975, 0.9997, 0.9992,\n",
       "        0.9905, 0.9879, 0.9910, 0.8425, 0.9679, 0.9963, 0.9773, 0.9980, 0.4833,\n",
       "        0.9988, 0.9881, 0.9975, 0.9986, 0.9981, 0.9972, 0.7975, 0.7800, 0.4504,\n",
       "        0.7400, 0.9999, 0.9999, 0.5489, 0.0531, 0.5702, 0.9877, 0.2686, 0.4023,\n",
       "        0.7521, 0.6226, 0.3085], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1==out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 306, 51200])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_product(numbers: List[int]) -> Tuple[int, int]:\n",
    "    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n",
    "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
    "    >>> sum_product([])\n",
    "    (0, 1)\n",
    "    >>> sum_product([1, 2, 3, 4])\n",
    "    (10, 24)\n",
    "    \"\"\"\n",
    "    # write your code here\n",
    "    if len(numbers) == 0:\n",
    "        return (0, 1)\n",
    "    else:\n",
    "        return (sum(numbers), prod(numbers))\n",
    "\n",
    "\n",
    "def prod(numbers: List[int]) -> int:\n",
    "    \"\"\" For a given list of integers, return a product of all the integers in a list.\n",
    "    Empty product should be equal to 1.\n",
    "    >>> prod([])\n",
    "    1\n",
    "    >>> prod([1, 2, 3, 4])\n",
    "    24\n",
    "    \"\"\"\n",
    "    # write your code here\n",
    "    if len(numbers) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return numbers[0] * prod(numbers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 24)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_product([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = \"asf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 4, 0, 0, 2, 4, 0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_nested_parens('(()()) ((())) () ((())()())')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tokenizer.decode(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please complete the following Python code without providing any additional tasks such as testing or explanations\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\"\n",
      "    return sum(abs(x - mean(numbers)) for x in numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def mean(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mean.\n",
      "    >>> mean([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def median(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the median.\n",
      "    >>> median([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sorted(numbers)[len(numbers) / 2]\n",
      "\n",
      "\n",
      "def mode(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mode.\n",
      "    >>> mode([1.0, 2.0, 3.0, 4.0])\n",
      "    2.0\n",
      "    \"\"\"\n",
      "    return numbers.count(max(numbers))\n",
      "\n",
      "\n",
      "def variance(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the variance.\n",
      "    >>> variance([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(x * (x - mean(numbers)) ** 2 for x in numbers) / (len(numbers) - 1)\n",
      "\n",
      "\n",
      "def standard_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the standard deviation.\n",
      "    >>>\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__name__ == \\\"__main__\\\"\" in test:\n",
    "    next_line = test.index('if __name__ == \"__main__\":')\n",
    "    test = test[:next_line].strip()\n",
    "    # print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please complete the following Python code without providing any additional tasks such as testing or explanations\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\"\n",
      "    return sum(abs(x - mean(numbers)) for x in numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def mean(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mean.\n",
      "    >>> mean([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def median(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the median.\n",
      "    >>> median([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sorted(numbers)[len(numbers) / 2]\n",
      "\n",
      "\n",
      "def mode(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mode.\n",
      "    >>> mode([1.0, 2.0, 3.0, 4.0])\n",
      "    2.0\n",
      "    \"\"\"\n",
      "    return numbers.count(max(numbers))\n",
      "\n",
      "\n",
      "def variance(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the variance.\n",
      "    >>> variance([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(x * (x - mean(numbers)) ** 2 for x in numbers) / (len(numbers) - 1)\n",
      "\n",
      "\n",
      "def standard_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the standard deviation.\n",
      "    >>>\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def filter_1(code: str) -> str:\n",
    "    code = code.split('if __name__ == \"__main__\":')[0]\n",
    "    code = code.split(\"if __name__ == '__main__':\")[0]\n",
    "\n",
    "    try:\n",
    "        exec(code)\n",
    "        return code\n",
    "    except Exception:\n",
    "        code = re.split('(def)', code)[:-2]\n",
    "        code = ''.join(code)\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = filter_1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please complete the following Python code without providing any additional tasks such as testing or explanations\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\"\n",
      "    return sum(abs(x - mean(numbers)) for x in numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def mean(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mean.\n",
      "    >>> mean([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def median(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the median.\n",
      "    >>> median([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sorted(numbers)[len(numbers) / 2]\n",
      "\n",
      "\n",
      "def mode(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mode.\n",
      "    >>> mode([1.0, 2.0, 3.0, 4.0])\n",
      "    2.0\n",
      "    \"\"\"\n",
      "    return numbers.count(max(numbers))\n",
      "\n",
      "\n",
      "def variance(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the variance.\n",
      "    >>> variance([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(x * (x - mean(numbers)) ** 2 for x in numbers) / (len(numbers) - 1)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割字符串\n",
    "lines = test.split('\\n')\n",
    "# 去掉第一行\n",
    "new_text = '\\n'.join(lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\"\n",
      "    return sum(abs(x - mean(numbers)) for x in numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def mean(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mean.\n",
      "    >>> mean([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "\n",
      "def median(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the median.\n",
      "    >>> median([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sorted(numbers)[len(numbers) / 2]\n",
      "\n",
      "\n",
      "def mode(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the mode.\n",
      "    >>> mode([1.0, 2.0, 3.0, 4.0])\n",
      "    2.0\n",
      "    \"\"\"\n",
      "    return numbers.count(max(numbers))\n",
      "\n",
      "\n",
      "def variance(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate the variance.\n",
      "    >>> variance([1.0, 2.0, 3.0, 4.0])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    return sum(x * (x - mean(numbers)) ** 2 for x in numbers) / (len(numbers) - 1)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def intersperse(numbers: List[int], delimeter: int) -> List[int]:\n",
    "    \"\"\" Insert a number 'delimeter' between every two consecutive elements of input list `numbers'\n",
    "    >>> intersperse([], 4)\n",
    "    []\n",
    "    >>> intersperse([1, 2, 3], 4)\n",
    "    [1, 4, 2, 4, 3]\n",
    "    \"\"\"\n",
    "    # write your response here\n",
    "    return [n for n in numbers if n % delimeter == 0] + [n for n in numbers if n % delimeter!= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersperse([1, 2, 3], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction  = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this function prints hello world\n",
      "def hello():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello2():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello3():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello4():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello5():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello6():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "# this function prints hello world\n",
      "def hello7():\n",
      "    print(\"Hello\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/StarCoder-1B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/StarCoder-1B\").to(device)\n",
    "inputs = tokenizer(\"# this function prints hello world\", return_tensors=\"pt\").to(device)\n",
    "sample = model.generate(**inputs, max_length=128)\n",
    "\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side='left'\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "human_eval_path = \"/home/liuchao/shushanfu/LMOps/data/HumanEval.jsonl\"\n",
    "dataframe = pd.read_json(human_eval_path,lines=True)\n",
    "prompts = dataframe['prompt'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(insruction,input):\n",
    "    INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "{insruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    \n",
    "    if input==\"\":\n",
    "        INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "{insruction}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    return INSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_solution(insruction,input):\n",
    "    INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "{insruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Solution:\"\"\"\n",
    "    \n",
    "    if input==\"\":\n",
    "        INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "{insruction}\n",
    "\n",
    "### Solution:\"\"\"\n",
    "    return INSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"\"\"\n",
    "Check if in given list of numbers, are any two numbers closer to each other than\n",
    "    given threshold.\n",
    "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
    "    False\n",
    "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
    "    True\n",
    "from typing import List\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "intput2 = prompts[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Create a php code to capitalize the first letter of every word in a string.\"\n",
    "input = \"string = \\u201cwelcome to the world of coding\\u201d\"\n",
    "intput2 = generate_prompt(instruction,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "def closest_integer(value):\n",
      "    '''\n",
      "    Create a function that takes a value (string) representing a number\n",
      "    and returns the closest integer to it. If the number is equidistant\n",
      "    from two integers, round it away from zero.\n",
      "\n",
      "    Examples\n",
      "    >>> closest_integer(\"10\")\n",
      "    10\n",
      "    >>> closest_integer(\"15.3\")\n",
      "    15\n",
      "\n",
      "    Note:\n",
      "    Rounding away from zero means that if the given number is equidistant\n",
      "    from two integers, the one you should return is the one that is the\n",
      "    farthest from zero. For example closest_integer(\"14.5\") should\n",
      "    return 15 and closest_integer(\"-14.5\") should return -15.\n",
      "    '''\n",
      "\n",
      "\n",
      "### Solution:\n"
     ]
    }
   ],
   "source": [
    "intput2 = generate_prompt_solution(intput2,\"\")\n",
    "print(intput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def closest_integer(value):\n",
      "    '''\n",
      "    Create a function that takes a value (string) representing a number\n",
      "    and returns the closest integer to it. If the number is equidistant\n",
      "    from two integers, round it away from zero.\n",
      "\n",
      "    Examples\n",
      "    >>> closest_integer(\"10\")\n",
      "    10\n",
      "    >>> closest_integer(\"15.3\")\n",
      "    15\n",
      "\n",
      "    Note:\n",
      "    Rounding away from zero means that if the given number is equidistant\n",
      "    from two integers, the one you should return is the one that is the\n",
      "    farthest from zero. For example closest_integer(\"14.5\") should\n",
      "    return 15 and closest_integer(\"-14.5\") should return -15.\n",
      "    '''\n",
      "    # write your code here\n",
      "    if value == \"0\":\n",
      "        return 0\n",
      "    if value == \"1\":\n",
      "        return 1\n",
      "    if value == \"2\":\n",
      "        return 2\n",
      "    if value == \"3\":\n",
      "        return 3\n",
      "    if value == \"4\":\n",
      "        return 4\n",
      "    if value == \"5\":\n",
      "        return 5\n",
      "    if value == \"6\":\n",
      "        return 6\n",
      "    if value == \"7\":\n",
      "        return 7\n",
      "    if value == \"8\":\n",
      "        return 8\n",
      "    if value == \"9\":\n",
      "        return 9\n",
      "    if value == \"10\":\n",
      "        return 10\n",
      "    if value == \"11\":\n",
      "        return 11\n",
      "    if value == \"12\":\n",
      "        return 12\n",
      "    if value == \"13\":\n",
      "        return 13\n",
      "    if value == \"14\":\n",
      "        return 14\n",
      "    if value == \"15\":\n",
      "        return 15\n",
      "    if value == \"16\":\n",
      "        return 16\n",
      "    if value == \"17\":\n",
      "        return 17\n",
      "    if value == \"18\":\n",
      "        return 18\n",
      "    if value == \"19\":\n",
      "        return 19\n",
      "    if value == \"20\":\n",
      "        return 20\n",
      "    if value == \"21\":\n",
      "        return 21\n",
      "    if value == \"22\":\n",
      "        return 22\n",
      "    if value == \"23\":\n",
      "        return 23\n",
      "    if value == \"24\":\n",
      "        return 24\n",
      "    if value == \"25\":\n",
      "        return 25\n",
      "    if value == \"26\":\n",
      "        return 26\n",
      "    if value == \"27\":\n",
      "        return 27\n",
      "    if value == \"28\":\n",
      "        return 28\n",
      "    if value == \"29\":\n",
      "        return 29\n",
      "    if value == \"30\":\n",
      "        return 30\n",
      "    if value == \"31\":\n",
      "        return 31\n",
      "    if value == \"32\":\n",
      "        return 32\n",
      "    if value == \"33\":\n",
      "        return 33\n",
      "    if value == \"34\":\n",
      "        return 34\n",
      "    if value == \"35\":\n",
      "        return 35\n",
      "    if value == \"36\":\n",
      "        return 36\n",
      "    if value == \"37\":\n",
      "        return 37\n",
      "    if value == \"38\":\n",
      "        return 38\n",
      "    if value == \"39\":\n",
      "        return 39\n",
      "    if value == \"40\":\n",
      "        return 40\n",
      "    if value == \"41\":\n",
      "        return 41\n",
      "    if value == \"42\":\n",
      "        return 42\n",
      "    if value == \"43\":\n",
      "        return 43\n",
      "    if value == \"44\":\n",
      "        return 44\n",
      "    if value == \"45\":\n",
      "        return 45\n",
      "    if value == \"46\":\n",
      "        return 46\n",
      "    if value == \"47\":\n",
      "        return 47\n",
      "    if value == \"48\":\n",
      "        return 48\n",
      "    if value == \"49\":\n",
      "        return 49\n",
      "    if value == \"50\":\n",
      "        return 50\n",
      "    if value == \"51\":\n",
      "        return 51\n",
      "    if value == \"52\":\n",
      "        return 52\n",
      "    if value == \"53\":\n",
      "        return 53\n",
      "    if value == \"54\":\n",
      "        return 54\n",
      "    if value == \"55\":\n",
      "        return 55\n",
      "    if value == \"56\":\n",
      "        return 56\n",
      "    if value == \"57\":\n",
      "        return 57\n",
      "    if value == \"58\":\n",
      "        return 58\n",
      "    if value == \"59\":\n",
      "        return 59\n",
      "    if value == \"60\":\n",
      "        return 60\n",
      "    if value == \"61\":\n",
      "        return 61\n",
      "    if value == \"62\":\n",
      "        return 62\n",
      "    if value == \"63\":\n",
      "        return 63\n",
      "    if value == \"64\":\n",
      "        return 64\n",
      "    if value == \"65\":\n",
      "        return 65\n",
      "    if value == \"66\":\n",
      "        return 66\n",
      "    if value == \"67\":\n",
      "        return \n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "gen_prompt = \"Please complete the following Python code without providing any additional tasks such as testing or explanations\\n\"\n",
    "end_prompt = \"    # write your code here\"\n",
    "# end_prompt = \"### Solution\"\n",
    "# test = \"Please complete the following code\"\n",
    "inputs = intput2 + end_prompt\n",
    "# inputs =gen_prompt + intput2 + end_prompt\n",
    "# inputs =generate_prompt(intput2)\n",
    "\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\").to(device)\n",
    "generation_config = GenerationConfig(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample= False,\n",
    "    # temperature=0.7,\n",
    "    max_length= 1024,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # pad_token_id = tokenizer.pad_token_id,\n",
    "    # top_p=0.8\n",
    ")\n",
    "sample = model.generate(**inputs,generation_config = generation_config)\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
    "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
    "    around the mean of this dataset.\n",
    "    Mean Absolute Deviation is the average absolute difference between each\n",
    "    element and a centerpoint (mean in this case):\n",
    "    MAD = average | x - x_mean |\n",
    "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    mean = sum(numbers) / len(numbers)\n",
    "    return sum([abs(x - mean) for x in numbers]) / len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "12\n",
      "12\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,13,3):\n",
    "    print(i)\n",
    "    print(i+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_matrix(M):\n",
    "    \"\"\"\n",
    "    Write a function to sort a given matrix in ascending order according to the sum of its rows.\n",
    "    >>> sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])\n",
    "    [[1, 1, 1], [1, 2, 3], [2, 4, 5]]\n",
    "    >>> sort_matrix([[1, 2, 3], [(- 2), 4, (- 5)], [1, (- 1), 1]])\n",
    "    [[(- 2), 4, (- 5)], [1, (- 1), 1], [1, 2, 3]]\n",
    "    >>> sort_matrix([[5, 8, 9], [6, 4, 3], [2, 1, 4]])\n",
    "    [[2, 1, 4], [6, 4, 3], [5, 8, 9]]\n",
    "    \"\"\"\n",
    "    # Initialize the matrix to store the sorted matrix\n",
    "    sorted_matrix = [[0 for _ in range(len(M[0]))] for _ in range(len(M))]\n",
    "\n",
    "    # Iterate through the matrix and calculate the sum of the rows\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M[0])):\n",
    "            sorted_matrix[i][j] = M[i][j] + sorted_matrix[i][j]\n",
    "\n",
    "    # Return the sorted matrix\n",
    "    return sorted_matrix\n",
    "\n",
    "# Test the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [2, 4, 5], [1, 1, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_print_statements(code: str) -> str:\n",
    "    # 匹配任意前后空白字符，可能存在的print语句及其后的任意内容，直到行尾\n",
    "    # pattern = r'^\\s*print\\(.*\\).*$(\\r?\\n|\\r)'\n",
    "    pattern = r'^\\s*print\\(.*?\\)\\s*$'\n",
    "    # 使用 MULTILINE 标志来让 ^ 和 $ 分别匹配每行的开始和结束，而不是整个字符串的开始和结束\n",
    "    return re.sub(pattern, '', code, flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = \"\"\"\n",
    "def no_of_subsequences(arr, k):\n",
    "    \\\"\\\"\\\"\n",
    "    Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
    "    >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
    "    11\n",
    "    >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
    "    9\n",
    "    >>> no_of_subsequences([5, 6, 7, 8], 15)\n",
    "    4\n",
    "    \\\"\\\"\\\"\n",
    "        # write your code here\n",
    "        count = 0\n",
    "        for i in range(len(arr)):\n",
    "            for j in range(i+1, len(arr)):\n",
    "                if arr[i] * arr[j] < k:\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "# Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
    "# >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
    "# 11\n",
    "# >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
    "# 9\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def bell_number(n):\n",
      "    \"\"\"\n",
      "    Write a function to find the number of ways to partition a set of bell numbers.\n",
      "    >>> bell_number(2)\n",
      "    2\n",
      "    >>> bell_number(10)\n",
      "    115975\n",
      "    >>> bell_number(56)\n",
      "    6775685320645824322581483068371419745979053216268760300\n",
      "    \"\"\"\n",
      "    # Initialize the result\n",
      "    result = 0\n",
      "    # Loop through the numbers\n",
      "    for i in range(1, n + 1):\n",
      "        # Check if the number is divisible by any number between 2 and n\n",
      "        if i % (n + 1) == 0:\n",
      "            result += 1\n",
      "    return result\n",
      "\n",
      "# Test the function\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_print_statements(st1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def no_of_subsequences(arr, k):\n",
      "    \"\"\"\n",
      "    Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "    >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "    11\n",
      "    >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "    9\n",
      "    >>> no_of_subsequences([5, 6, 7, 8], 15)\n",
      "    4\n",
      "    \"\"\"\n",
      "        # write your code here\n",
      "        count = 0\n",
      "        for i in range(len(arr)):\n",
      "            for j in range(i+1, len(arr)):\n",
      "                if arr[i] * arr[j] < k:\n",
      "                    count += 1\n",
      "        return count\n",
      "\n",
      "# Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "# >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "# 11\n",
      "# >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "# 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st1 = st1.split('if __name__ == \"__main__\":')[0]\n",
    "print(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def no_of_subsequences(arr, k):\n",
      "    \"\"\"\n",
      "    Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "    >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "    11\n",
      "    >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "    9\n",
      "    >>> no_of_subsequences([5, 6, 7, 8], 15)\n",
      "    4\n",
      "    \"\"\"\n",
      "        # write your code here\n",
      "        count = 0\n",
      "        for i in range(len(arr)):\n",
      "            for j in range(i+1, len(arr)):\n",
      "                if arr[i] * arr[j] < k:\n",
      "                    count += 1\n",
      "        return count\n",
      "\n",
      "# Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "# >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "# 11\n",
      "# >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "# 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def no_of_subsequences(arr, k):\n",
      "    \"\"\"\n",
      "    Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "    >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "    11\n",
      "    >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "    9\n",
      "    >>> no_of_subsequences([5, 6, 7, 8], 15)\n",
      "    4\n",
      "    \"\"\"\n",
      "        # write your code here\n",
      "        count = 0\n",
      "        for i in range(len(arr)):\n",
      "            for j in range(i+1, len(arr)):\n",
      "                if arr[i] * arr[j] < k:\n",
      "                    count += 1\n",
      "        return count\n",
      "\n",
      "# Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
      "# >>> no_of_subsequences([1, 2, 3, 4], 10)\n",
      "# 11\n",
      "# >>> no_of_subsequences([4, 8, 7, 2], 50)\n",
      "# 9\n"
     ]
    }
   ],
   "source": [
    "code = st1\n",
    "code = code.split(\"if __name__ == '__main__':\")[0]\n",
    "code = code.replace(gen_prompt,\"\")\n",
    "\n",
    "code = code.replace(end_prompt_1,\"\")\n",
    "\n",
    "# 去掉print\n",
    "pattern = r'^\\s*print\\(.*\\).*$(\\r?\\n|\\r)'\n",
    "code = re.sub(pattern, '', code, flags=re.MULTILINE)\n",
    "\n",
    "pattern = r'^\\s*print\\(.*?\\)\\s*$'\n",
    "code = re.sub(pattern, '', code, flags=re.MULTILINE)\n",
    "pattern = re.compile(r'^.*\\bprint\\b.*$', re.MULTILINE)\n",
    "code = re.sub(pattern, '', code)\n",
    "\n",
    "\n",
    "# 去掉#Test\n",
    "code = code.split(\"# Test\")[0].strip()\n",
    "\n",
    "code = code.split(\"# testing\")[0].strip()\n",
    "\n",
    "code = code.split(\"#Test\")[0].strip()\n",
    "print(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/liuchao/shushanfu/LMOps/results/starcoder/train/kd_fkl/6723\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/liuchao/shushanfu/LMOps/results/starcoder/train/kd_fkl/6723\").to(device)\n",
    "inputs = tokenizer(\"# this function prints hello world\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(prompt: str, model_path:str) -> str:\n",
    "    if \"starcoder\" in model_path.lower():\n",
    "        prompt = \"<fim_prefix>\" + prompt + \"<fim_suffix><fim_middle>\"\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"Please complete the following Python code without providing any additional tasks such as testing or explanations\\n\"\n",
    "            + prompt\n",
    "        )\n",
    "    if \"starchat\" in model_path.lower():\n",
    "        prompt = f\"<|system|>\\n<|end|>\\n<|user|>{prompt}<|end|>\\n<|assistant|>\"\n",
    "    return prompt\n",
    "def replace_gen_prompt(prompt: str, model_path:str) -> str:\n",
    "    if \"starcoder\" in model_path.lower():\n",
    "        prompt = prompt.replace(\"<fim_prefix>\",\"\")\n",
    "        prompt = prompt.replace(\"<fim_suffix><fim_middle>\",\"\")\n",
    "    else:\n",
    "        prompt = prompt.replace(\"Please complete the following Python code without providing any additional tasks such as testing or explanations\\n\",\"\")\n",
    "    if \"starchat\" in model_path.lower():\n",
    "        prompt = prompt.replace(\"<|system|>\\n<|end|>\\n<|user|>\",\"\")\n",
    "        prompt = prompt.replace(\"<|end|>\\n<|assistant|>\",\"\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "human_eval_path = \"/home/liuchao/shushanfu/LMOps/data/HumanEval.jsonl\"\n",
    "dataframe = pd.read_json(human_eval_path,lines=True)\n",
    "prompts = dataframe['prompt'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"What would be the output of the following JavaScript snippet?\\nlet area = 6 * 5;\\nlet radius = area / 3.14;\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>What would be the output of the following JavaScript snippet?\n",
      "let area = 6 * 5;\n",
      "let radius = area / 3.14;\n",
      "<fim_suffix><fim_middle>\n"
     ]
    }
   ],
   "source": [
    "inputs = gen_prompt(str1,\"starcoder\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>def remove_Occ(s, ch):\n",
      "    \"\"\"\n",
      "    Write a python function to remove first and last occurrence of a given character from the string.\n",
      "    >>> remove_Occ('hello', 'l')\n",
      "    'heo'\n",
      "    >>> remove_Occ('abcda', 'a')\n",
      "    'bcd'\n",
      "    >>> remove_Occ('PHP', 'P')\n",
      "    'H'\n",
      "    \"\"\"\n",
      "    <fim_suffix><fim_middle>\n"
     ]
    }
   ],
   "source": [
    "inputs_2 = \"\"\"<fim_prefix>def remove_Occ(s, ch):\\n    \\\"\\\"\\\"\\n    Write a python function to remove first and last occurrence of a given character from the string.\\n    >>> remove_Occ('hello', 'l')\\n    'heo'\\n    >>> remove_Occ('abcda', 'a')\\n    'bcd'\\n    >>> remove_Occ('PHP', 'P')\\n    'H'\\n    \\\"\\\"\\\"\\n    <fim_suffix><fim_middle>\"\"\"\n",
    "# inputs = gen_prompt(inputs,\"starcoder\")\n",
    "print(inputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs == inputs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>What would be the output of the following JavaScript snippet?\n",
      "let area = 6 * 5;\n",
      "let radius = area / 3.14;\n",
      "<fim_suffix><fim_middle>console.log(radius);\n",
      "\n",
      "// Output: 10.265482457437061<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(inputs, return_tensors=\"pt\").to(device)\n",
    "sample = model.generate(**inputs, max_length=512)\n",
    "\n",
    "print(tokenizer.batch_decode(sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, CodeGenConfig, CodeGenForCausalLM, Trainer, TrainingArguments, TrainerCallback, TrainerState, TrainerControl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = glob.glob(os.path.join('/home/yanmeng/lidong/code/pretrain_distill/pretrain/pretrain_data/', \"train_*.parquet\"), recursive=True)\n",
    "VAl_FILES = glob.glob(os.path.join('/home/yanmeng/lidong/code/pretrain_distill/pretrain/validation_data/', \"val_*.parquet\"), recursive=True)\n",
    "TRAIN_FILES = TRAIN_FILES[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/yanmeng/lidong/code/pretrain_distill/pretrain/pretrain_data/train_starcoder_0000000016.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 2.0\n",
    "ALPHA = 0.5\n",
    "wandb_log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dtype = np.uint16\n",
    "dataset = load_dataset(\n",
    "        path=\"parquet\",\n",
    "        data_files=TRAIN_FILES,\n",
    "        split=\"train\",\n",
    "        cache_dir=\".cache\",\n",
    "        keep_in_memory=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1029176\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_dir = \"processed_data/starcoderdata/full/codegen/train.jsonl\"\n",
    "with open(output_dir, \"w\") as jsonl_file:\n",
    "  for i in range(len(dataset)):\n",
    "          # 创建 JSON 对象，假设 'instruction' 字段对应 'text'\n",
    "          json_record = {\n",
    "              \"instruction\": dataset[i]['text'],  # 将 text 保存到 instruction 字段\n",
    "              \"prompt\": \"\",\n",
    "              \"input\": \"\",\n",
    "              \"output\": \"\"\n",
    "          }\n",
    "          \n",
    "          # 写入 JSONL 文件中\n",
    "          jsonl_file.write(json.dumps(json_record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from phenom.utils.utils import setmask, findindex, pad_to_pow_2\\nfrom phenom import MakeWaveformSeries\\nimport numpy as np\\n\\n\\n\\n#TODO: Refactor match code\\n#TODO: turn the masking and selection of the frequency\\n#series into a method which can be access outside.\\n#This is very useful for debugging purposes.\\n\\nclass Match(object):\\n    \"\"\"docstring for Match\"\"\"\\n    def __init__(self):\\n        # print \"init Match class\"\\n        pass\\n\\n    ################################################\\n    # TODO: the input to this function, ph1 and ph2\\n    # should be members of a `FrequencySeries` class\\n    # with attributes flist, deltaF etc.\\n    def match(self, ph1, ph2, fmin=0, fmax=0, psd_fun=None, zpf=5):\\n        \"\"\"\\n        input:\\n            ph1 : instance of phenom.MakeWaveformSeries\\n            ph2 : instance of phenom.MakeWaveformSeries\\n\\n        computes the overlap between normalised\\n        templates (h_plus only!),\\n        optimised over time and phase.\\n        Templates must be in frequency domain.\\n        ph1, ph2 = ins'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/deepseek-coder-1.3b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/liuchao/shushanfu/LMOps/checkpoints/deepseek-coder-1.3b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    从 JSONL 文件中加载数据\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))  \n",
    "    return data\n",
    "data = load_jsonl(\"/home/liuchao/shushanfu/LMOps/data/magic/raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\\n\\nThe script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \\n\\n```python\\n  # Establish an integer list\\n  arr = [1, 2, 3, 4]\\n\\n  # Determine the length of the list\\n  n = len(arr)\\n\\n  # Traverse the list and output each individual element\\n  for i in range(n+1):\\n      print(arr[i])\\n```\",\n",
       " 'response': '```python\\n# Establish an integer list\\narr = [1, 2, 3, 4]\\n\\n# Determine the length of the list\\nn = len(arr)\\n\\n# Initialize index at 0\\ni = 0\\n\\n# Traverse the list and output each individual element\\nwhile i < n:\\n    print(arr[i])\\n    i += 1\\n```\\nIn the given code, it tries to access `arr[n]` which is out of bounds as python list indexing starts from 0 and ends at n-1 for a list of length n.\\nAlso, I used `while` loop as per your request. By initializing `i=0` before the loop and `i += 1` within the loop, we can iterate over the list. This iteration continues until `i` is less than `n`, the length of the list. The `while` loop will not proceed if the list is empty so it correctly handles empty lists.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[0]['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\n",
      "\n",
      "The script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  for i in range(n+1):\n",
      "      print(arr[i])\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_prompt = \"\\n# Write your code here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\n",
      "\n",
      "The script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  for i in range(n+1):\n",
      "      print(arr[i])\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\n",
      "\n",
      "The script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  for i in range(n+1):\n",
      "      print(arr[i])\n",
      "```\n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  i = 0\n",
      "  while i < n:\n",
      "      print(arr[i])\n",
      "      i += 1\n",
      "```\n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  for i in range(n):\n",
      "      print(arr[i])\n",
      "```\n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  i = 0\n",
      "  while i < n:\n",
      "      print(arr[i])\n",
      "      i += 1\n",
      "```\n",
      "\n",
      "```python\n",
      "  # Establish an integer list\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Determine the length of the list\n",
      "  n = len(arr)\n",
      "\n",
      "  # Traverse the list and output each individual element\n",
      "  for i in range(n):\n",
      "      print(arr[i])\n",
      "```\n",
      "\n",
      "```python\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "generation_config = GenerationConfig(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample= False,\n",
    "    # temperature=0.7,\n",
    "    max_length= 512,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # top_p=0.8\n",
    ")\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\")\n",
    "sample = model.generate(**inputs,generation_config = generation_config)\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
